{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_BackProp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0BUjqiFCAoAb",
        "AeK_f_DuyoeN",
        "XMp-qxiyAwLO",
        "NexrLXziyuBn",
        "Xg2_MQndzlnz",
        "4pxzJtTE1BF0",
        "rexhWjRYy71X",
        "bMSyyXEsA1OF",
        "TrW2caLupYqs",
        "Ud477csup2v7",
        "iNb6SrStmUjk",
        "dSYbi6kRmrLM",
        "MGyT7utqloZq",
        "fg-oQq6v7rEk",
        "d2bWXzcG7o8k",
        "MLqQbdZDp0tF",
        "VCvH4HlUe6hm",
        "LcGh6JpptkPt",
        "T0kDy5eRtoOM",
        "GKWQs_-5tqhd",
        "7VvUj4Z3tsr_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyKbeDHPxXYh",
        "colab_type": "text"
      },
      "source": [
        "# Team BackProp - Data Science Notebook\n",
        "\n",
        "During exploration of the neural architecture, we used copies of this notebook to be able to easily process data whilst keeping our models intact. \n",
        "\n",
        "The general overview of the data modelling pipeline is as follows:\n",
        "\n",
        "1. Import KMNIST Data\n",
        "2. Data preprocess and augmentate\n",
        "3. Develop neural network model\n",
        "4. Cross validate model\n",
        "    - At this stage we decide whether to keep the model for full training or remodify the network again to improve it.\n",
        "5. Hyperparameter Tuning\n",
        "6. Train on the full dataset\n",
        "7. Save model and Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPZJdQrwmPYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUjqiFCAoAb",
        "colab_type": "text"
      },
      "source": [
        "## Pipeline Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeK_f_DuyoeN",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRx8ivmoKxj",
        "colab_type": "code",
        "outputId": "aaa0dcee-2384-4bff-facc-f09bfe6f3b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Dataset \n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage, RandomResizedCrop, RandomAffine\n",
        "import random\n",
        "import itertools\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pickle\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwfMUJGoM8C",
        "colab_type": "code",
        "outputId": "0c047b37-11cc-41d5-f43d-a5beb44b5008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMp-qxiyAwLO",
        "colab_type": "text"
      },
      "source": [
        "### Import KMNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUPcM99Nmk_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the datasets\n",
        "X_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-imgs.npy\") /255\n",
        "y_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-labels.npy\")\n",
        "X_test_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-test-imgs.npy\") /255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3r09aK-nZUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the classmap as a dictionary\n",
        "classmap = {}\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist_classmap.csv', 'r') as csvfile:\n",
        "   spamreader = csv.reader(csvfile, delimiter=',')\n",
        "   next(spamreader)\n",
        "   for row in spamreader:\n",
        "       classmap[row[0]] = row[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ_PzPsjp5wN",
        "colab_type": "code",
        "outputId": "227fc236-96ca-43c7-8fed-f1980960e66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# Check if we imported correctly\n",
        "plt.imshow(X_train_orig[104])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbed439dd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWH4ip1h+IqdYfiKn/g8sgxvrYTasrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NexrLXziyuBn",
        "colab_type": "text"
      },
      "source": [
        "## Processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2_MQndzlnz",
        "colab_type": "text"
      },
      "source": [
        "### Train, Validate and Evaluate Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqSyDu7jy0l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # the dimension here was changed to match our KMNIST's dimension\n",
        "        a2 = model(X.view(-1, 1, 28, 28).float()) \n",
        "        \n",
        "        loss = criterion(a2, y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            # the dimension here was changed to match our KMNIST's dimension\n",
        "            a2 = model(X.view(-1, 1, 28, 28).float())\n",
        "            \n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            # the dimension here was changed to match our KMNIST's dimension\n",
        "            a2 = model(X.view(-1, 1, 28, 28).float())\n",
        "            \n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pxzJtTE1BF0",
        "colab_type": "text"
      },
      "source": [
        "### Training Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfDvaqlj1Ec7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(wd, lrt, model, train_loader, validate_loader):\n",
        "  set_seed(seed)\n",
        "  model = model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lrt, betas=(0.9, 0.999), eps=1e-08, weight_decay=wd, amsgrad=False)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(n_epochs):\n",
        "      logs = {}\n",
        "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "      logs['' + 'log loss'] = train_loss.item()\n",
        "      logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "      validation_loss, validation_accuracy = validate(model, criterion, validate_loader)\n",
        "      logs['val_' + 'log loss'] = validation_loss.item()\n",
        "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "      liveloss.update(logs)\n",
        "      liveloss.draw()\n",
        "\n",
        "  return liveloss, validation_loss, validation_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rexhWjRYy71X",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6FQzIZ_zDKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold_datasets(n_splits, X_train_orig, y_train_orig, trans=True, verbatim=False):\n",
        "  '''Wrapper function that returns a list of train/val datasets which have been \n",
        "     subjected to the KFold method. \n",
        "  '''\n",
        "  \n",
        "  kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  fold_train_loader = [] # list of shuffled training dataloaders\n",
        "  fold_validation_loader = [] # list of shuffled validation dataloaders\n",
        "\n",
        "  for train_index, test_index in kf.split(X_train_orig, y_train_orig):\n",
        "    if verbatim: print(\"TRAIN:\", train_index, \"Validation:\", test_index)\n",
        "    X_train, X_val = X_train_orig[train_index], X_train_orig[test_index]\n",
        "    y_train, y_val = y_train_orig[train_index], y_train_orig[test_index]\n",
        "\n",
        "    if verbatim: print(\"train size:\", X_train.shape, \"test size:\", X_val.shape)\n",
        "\n",
        "    # Convert to tensor\n",
        "    X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "    X_val, y_val = torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "    \n",
        "    # Find mean std\n",
        "    mean1, std1 = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "    # make Custom set\n",
        "    train_dataset = CustomImageTensorDataset(X_train, y_train.long(), transform=trans, mean=mean1, std=std1)\n",
        "    validation_dataset = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean1, std=std1)\n",
        "\n",
        "    # initialize the data-loaders\n",
        "    fold_train_loader.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4))\n",
        "    fold_validation_loader.append(DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NN7nOVyzxdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_kfold(wd, lrt, fold_train_loader, fold_validation_loader):\n",
        "  \"\"\" function to easily train the model with weight_decay as input parameter.\n",
        "  \n",
        "      HOW TO RUN THE FUNCTION:\n",
        "      fold_train_loader, fold_validation_loader = kfold_datasets(5, X_train_orig, y_train_orig, False)\n",
        "      lloss, loss, acc = train_model_kfold(weight_decay[3], fold_train_loader, fold_validation_loader)\n",
        "  \"\"\"\n",
        "  \n",
        "  fold_liveloss = []\n",
        "  fold_loss = 0.\n",
        "  fold_acc = 0.\n",
        "  for fold in range(len(fold_train_loader)):\n",
        "    # CHANGE THE MODEL HERE:\n",
        "    model = LeNet5()\n",
        "\n",
        "    liveloss, val_loss, val_acc = train_model(wd, lrt, model, fold_train_loader[fold], fold_validation_loader[fold])\n",
        "    fold_liveloss.append(liveloss)\n",
        "    fold_loss += val_loss\n",
        "    fold_acc += val_acc\n",
        "    print(\"fold:\", fold)\n",
        "    \n",
        "  print(\"Averaged Accuracy: \", (fold_acc/len(fold_train_loader))*100)\n",
        "  return fold_liveloss, fold_loss, fold_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjiHC9fU0lbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMSyyXEsA1OF",
        "colab_type": "text"
      },
      "source": [
        "## Image Preprocessing and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8JjQRgsWMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomImageTensorDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None, mean=False, std=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data.reshape(-1,1,28,28)\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "        # Find mean and standard dev\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "        \n",
        "        self.Rotation = Compose([\n",
        "                                  ToPILImage(),\n",
        "                                   RandomRotation(10),\n",
        "                                   ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                ])\n",
        "\n",
        "        self.RotandCrop = Compose([\n",
        "                                  ToPILImage(),\n",
        "                                   RandomResizedCrop(size=(28,28), scale=(0.8,1)),\n",
        "                                  ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                 ])\n",
        "        \n",
        "        self.Affine = Compose([ToPILImage(),\n",
        "                                   RandomAffine(10, shear=10),\n",
        "                                   ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                ])\n",
        " \n",
        "        \n",
        "        self.Norm = Compose([Normalize(mean=[self.mean], std=[self.std])\n",
        "                                 ])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        assert (self.mean != False), \"Asign a mean\"\n",
        "        assert (self.mean != False), \"Asign a std\"\n",
        "        \n",
        "        if self.transform:\n",
        "            x = random.random()\n",
        "            if 0<= x<0.2: # rotate\n",
        "              sample = self.Rotation(sample)\n",
        "            if 0.2<= x<0.4: # resize crop\n",
        "              sample = self.RotandCrop(sample)\n",
        "            if 0.4<= x<0.7: # shear crop\n",
        "              sample= self.Affine(sample)\n",
        "              \n",
        "            else: # none\n",
        "              sample = self.Norm(sample)\n",
        "        else:\n",
        "           sample = self.Norm(sample)\n",
        "            \n",
        "        return sample, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBQNzrYJ7PEM",
        "colab_type": "code",
        "outputId": "c5b998b3-06c8-4e7d-8863-2d47adc2e1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "source": [
        "# Check if our data augmentation/preprocessing works\n",
        "\n",
        "# Create a new custom image dataset:\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "mean1, std1 = torch.mean(X_train), torch.std(X_train)\n",
        "dset = CustomImageTensorDataset(X_train, y_train, transform=True, mean=mean1, std=std1 )\n",
        "\n",
        "# Make a dataloader to access the PIL images of a batch size of 25\n",
        "loader = DataLoader(dset, batch_size=25, shuffle=True)\n",
        "\n",
        "# Create an iter object to cycle through dataloader\n",
        "train_iter = iter(loader)\n",
        "imgs, labels = train_iter.next()\n",
        "\n",
        "print(imgs.shape)\n",
        "print('max:',imgs.max())\n",
        "\n",
        "# plot our batch of images with label names\n",
        "fig, axarr = plt.subplots(5,5,figsize=(8,8))\n",
        "fig.tight_layout()\n",
        "for img, label, axs in zip(imgs, labels, axarr.flatten()):\n",
        "    axs.set_title(classmap[str(label.numpy())] + \"   \" + str(label.numpy()))\n",
        "    axs.imshow(img.numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25, 1, 28, 28])\n",
            "max: tensor(6.1103)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAI6CAYAAADWqBk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwzAMwzC25P8BIr4C8Yle3kMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrW2caLupYqs",
        "colab_type": "text"
      },
      "source": [
        "## 1. Model Development\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud477csup2v7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Architecture Analysis Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7Xk3rwp11R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp1(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp1, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(400, 256, bias=True)\n",
        "    self.output = nn.Linear(256, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zToYy7v-sgrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp3(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 4x to better fit to the labels compared to 8x scaling\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp3, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(800, 512, bias=True)\n",
        "    self.output = nn.Linear(512, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG80gvW7U9sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp4(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      We have now provided a \"reasonable\" guess of the filters and paddings \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp4, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(144, 128, bias=True)\n",
        "    self.output = nn.Linear(128, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9B3jjq2scot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp5(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 8x but with an addional convolutional layer \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp5, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    \n",
        "    # additional layer\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    \n",
        "    self.conv_7 = nn.Conv2d(24, 24, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_10 = nn.Linear(144, 100, bias=True)\n",
        "    self.output = nn.Linear(100, 10, bias=True)\n",
        "    \n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    \n",
        "    x = self.act(self.conv_6(x))\n",
        "    \n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.act(self.conv_8(x))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ_3_vYFFgM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp6(nn.Module):\n",
        "  \"\"\" Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 4x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      We have now provided a \"reasonable\" guess of the filters and paddings \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp6, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(288, 200, bias=True)\n",
        "    self.output = nn.Linear(200, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD0WhU72wmri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp7(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      +1 classification layer\n",
        "      \n",
        "      We provided a \"reasonable\" guess of the filters\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp7, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(144, 100, bias=True)\n",
        "    self.linear_10 = nn.Linear(100, 70, bias=True)\n",
        "    self.output = nn.Linear(70, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1NAO0w07E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp8(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +4 Classification layers\n",
        "      +x4 parameters\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp8, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(48, 48, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(288, 200, bias=True)\n",
        "    self.linear_11 = nn.Linear(200, 130, bias=True)\n",
        "    self.linear_12 = nn.Linear(130, 90, bias=True)\n",
        "    self.linear_13 = nn.Linear(90, 60, bias=True)\n",
        "    self.linear_14 = nn.Linear(60, 30, bias=True)\n",
        "    self.output = nn.Linear(30, 10, bias=True)\n",
        "    \n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.act(self.conv_8(x))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.act(self.linear_11(x))\n",
        "    x = self.act(self.linear_12(x))\n",
        "    x = self.act(self.linear_13(x))\n",
        "    x = self.act(self.linear_14(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTkKwEBHA3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp12(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +5 Classification layers\n",
        "      +x2 parameters - only halved the original params!\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      Added batch norm\n",
        "      Added drop out\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp12, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 24, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(24, 64, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(64, 96, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(96, 96, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(96, 96, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(96, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(576, 384, bias=True)\n",
        "    self.linear_11 = nn.Linear(384, 192, bias=True)\n",
        "    self.linear_12 = nn.Linear(192, 128, bias=True)\n",
        "    self.linear_13 = nn.Linear(128, 85, bias=True)\n",
        "    self.linear_14 = nn.Linear(85, 42, bias=True)\n",
        "    self.linear_15 = nn.Linear(42, 21, bias=True)\n",
        "    self.output = nn.Linear(21, 10, bias=True)\n",
        "    \n",
        "    # Batch Normalization\n",
        "    self.b1 = nn.BatchNorm2d(24)\n",
        "    self.b3 = nn.BatchNorm2d(64)\n",
        "    self.b5 = nn.BatchNorm2d(96)\n",
        "    self.b6 = nn.BatchNorm2d(96)\n",
        "    self.b7 = nn.BatchNorm2d(96)\n",
        "    self.b8 = nn.BatchNorm2d(64)\n",
        "    \n",
        "    self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.b1(self.conv_1(x)))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.b3(self.conv_3(x)))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.b5(self.conv_5(x)))\n",
        "    x = self.act(self.b6(self.conv_6(x)))\n",
        "    x = self.act(self.b7(self.conv_7(x)))\n",
        "    x = self.act(self.b8(self.conv_8(x)))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.dout(self.linear_10(x)))\n",
        "    x = self.act(self.dout(self.linear_11(x)))\n",
        "    x = self.act(self.dout(self.linear_12(x)))\n",
        "    x = self.act(self.dout(self.linear_13(x)))\n",
        "    x = self.act(self.dout(self.linear_14(x)))\n",
        "    x = self.act(self.dout(self.linear_15(x)))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWwKvQJlGBgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp24(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +5 Classification layers\n",
        "      +x2 parameters - only halved the original params!\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      Added batch norm\n",
        "      Added drop out\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp24, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 16, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(16, 42, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(42, 64, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(64, 42, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(378, 252, bias=True)\n",
        "    self.linear_11 = nn.Linear(252, 126, bias=True)\n",
        "    self.linear_12 = nn.Linear(126, 84, bias=True)\n",
        "    self.linear_13 = nn.Linear(84, 42, bias=True)\n",
        "    self.linear_14 = nn.Linear(42, 21, bias=True)\n",
        "    self.output = nn.Linear(21, 10, bias=True)\n",
        "    \n",
        "    # Batch Normalization\n",
        "    self.b1 = nn.BatchNorm2d(16)\n",
        "    self.b3 = nn.BatchNorm2d(42)\n",
        "    self.b5 = nn.BatchNorm2d(64)\n",
        "    self.b6 = nn.BatchNorm2d(64)\n",
        "    self.b7 = nn.BatchNorm2d(64)\n",
        "    self.b8 = nn.BatchNorm2d(42)\n",
        "    \n",
        "    self.dout = nn.Dropout(p=0.5) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.b1(self.conv_1(x)))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.b3(self.conv_3(x)))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.b5(self.conv_5(x)))\n",
        "    x = self.act(self.b6(self.conv_6(x)))\n",
        "    x = self.act(self.b7(self.conv_7(x)))\n",
        "    x = self.act(self.b8(self.conv_8(x)))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.dout(self.linear_10(x)))\n",
        "    x = self.act(self.dout(self.linear_11(x)))\n",
        "    x = self.act(self.dout(self.linear_12(x)))\n",
        "    x = self.act(self.dout(self.linear_13(x)))\n",
        "    x = self.act(self.dout(self.linear_14(x)))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNb6SrStmUjk",
        "colab_type": "text"
      },
      "source": [
        "### Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaqVRx4AmSLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSYbi6kRmrLM",
        "colab_type": "text"
      },
      "source": [
        "## 2. Cross Validation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTqJmL_YnFIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Cross_Validate(wd, lrt, transform=True, KFOLD=False, KFOLD_num=5):  \n",
        "  '''Wrapper function to choose to run either K-Fold Cross Validation or Single \n",
        "      Cross Validation.\n",
        "  '''\n",
        "  if KFOLD:\n",
        "    fold_train_loader, fold_validation_loader = kfold_datasets(KFOLD_num, X_train_orig, y_train_orig, False)\n",
        "    lloss, val_loss, val_acc = train_model_kfold(wd, lrt, fold_train_loader, fold_validation_loader)  \n",
        "  \n",
        "  else:\n",
        "    # Split into train and validation sets!\n",
        "    shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(X_train_orig, y_train_orig)\n",
        "    indices = [(t, v) for t, v in shuffler][0]\n",
        "    \n",
        "    X_train, y_train = X_train_orig[indices[0]].astype(float), y_train_orig[indices[0]]\n",
        "    X_val, y_val = X_train_orig[indices[1]].astype(float), y_train_orig[indices[1]]\n",
        "\n",
        "    X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "    X_val, y_val =  torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "\n",
        "    mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "    # Assemble tensor datasets\n",
        "    train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=transform, mean=mean, std=std)\n",
        "    val_ds = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "    # Assemble dataloaders\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "    \n",
        "    # CHANGE MODEL HERE:\n",
        "    model = AlexNet_Exp8().to(device)\n",
        "    lloss, val_loss, val_acc = train_model(wd, lrt, model, train_loader, val_loader)\n",
        "\n",
        "  return lloss, val_loss, val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9gWIPnnlCW",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnC8OBoanuvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialise training parameters:\n",
        "seed = 42\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmiv3rw6nryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run cross validation:\n",
        "lloss, val_loss, val_acc = Cross_Validate(0.0, 1e-4, transform=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47T54GxYn5La",
        "colab_type": "text"
      },
      "source": [
        "### Save Cross Validation Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtIg0iXCnzIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alexnet_exp8_logs = lloss.logs\n",
        "f = open(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/Model/AlexNet_exp8_logs.pkl\",\"wb\")\n",
        "pickle.dump(alexnet_exp8_logs,f)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGyT7utqloZq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Hyperparameter Tuning\n",
        "\n",
        "Hyper parameter searching has been turned off for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg-oQq6v7rEk",
        "colab_type": "text"
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbQCwZ7Q0t6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomSearch(iterations, train_loader, validate_loader):\n",
        "  max_acc = 0.0\n",
        "  opt_wd = 0.0\n",
        "  opt_lr = 0.0\n",
        "  \n",
        "  set_seed(seed)\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    # randomise our hyper parameters\n",
        "    weight_decay = 0.0\n",
        "    lr = 0.0 \n",
        "    \n",
        "    # Select from ranges of [1e-1 to 1e-4]\n",
        "    while np.isclose(weight_decay, 0.0):\n",
        "      power = int((random.random()*10)%5)+1\n",
        "      weight_decay = (5.*round(random.random()*10./5.) * (1./10.**power))\n",
        "\n",
        "    # Select from ranges of [1e-1 to 1e-4]\n",
        "    while np.isclose(lr, 0.0):\n",
        "      power = int((random.random()*10)%5)+1 \n",
        "      lr = 5.*round(random.random()*10./5.) * (1./10.**power)\n",
        "\n",
        "    print(\"Weight Decay: \", weight_decay)\n",
        "    print(\"Learn Rate: \", lr)\n",
        "    \n",
        "    # Change Model Here:\n",
        "    model = LeNet5()\n",
        "    lloss, val_loss, val_acc = train_model(weight_decay, lr, model, train_loader, validate_loader)\n",
        "\n",
        "    if val_acc > max_acc:\n",
        "      max_acc = val_acc\n",
        "      opt_wd = weight_decay\n",
        "      opt_lr = lr\n",
        "\n",
        "    return max_acc, [opt_wd, opt_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2bWXzcG7o8k",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZICLtlo587C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ParamDomain(params, range3=True):\n",
        "  grid_search = []\n",
        "  \n",
        "  for param in params:\n",
        "    count = 0\n",
        "    number = 1/param\n",
        "    s = set(str(param))\n",
        "    isFive = s.issuperset(\"5\")\n",
        "\n",
        "    while (number > 0):\n",
        "      number = number//10\n",
        "      count = count + 1\n",
        "    if not isFive:\n",
        "      count = count - 1\n",
        "    num = (1.0/10.0**count)\n",
        "    \n",
        "    if range3:\n",
        "      param_domain = []\n",
        "      param_domain.append(param - num*1)\n",
        "      param_domain.append(param)\n",
        "      param_domain.append(param + num*1)\n",
        "    else:\n",
        "      param_domain = []\n",
        "      param_domain.append(param - num*2)\n",
        "      param_domain.append(param - num*1)\n",
        "      param_domain.append(param)\n",
        "      param_domain.append(param + num*1)\n",
        "      param_domain.append(param + num*2)\n",
        "    \n",
        "    grid_search.append(param_domain)\n",
        "    \n",
        "  return grid_search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFzQVrhBcUPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_hyperpara(one_hyperpara, model, train_loader, validate_loader):\n",
        "  wd, lrt = one_hyperpara\n",
        "  lloss, loss, acc = train_model(wd, lrt, model, train_loader, validate_loader)\n",
        "  return lloss, loss, acc\n",
        "  \n",
        "def GridSearch(rand_params, train_loader, validate_loader, pseudo=True):\n",
        "  i = 0\n",
        "  lloss_list, loss_list, acc_list = [], [], []\n",
        "\n",
        "  if pseudo: # In grid search we may want to only find only the combinations that vary contiguously\n",
        "    grid = ParamDomain(params, False)\n",
        "    grid = np.array(grid)\n",
        "    grid = grid.transpose()\n",
        "    print(\"Total number of side by side searches: \", grid.shape[0])\n",
        "\n",
        "    for comb in grid:\n",
        "      # CHANGE MODELS HERE!\n",
        "      model = LeNet5()\n",
        "      wd = comb[0]\n",
        "      lrt = comb[1]\n",
        "      #mtm = comb[2]\n",
        "      \n",
        "      ll, l, a = train_model(wd, lrt, model, train_loader, validate_loader)\n",
        "      lloss_list.append(ll)\n",
        "      loss_list.append(l)\n",
        "      acc_list.append(a)\n",
        "      \n",
        "    lloss_list = np.array(lloss_list)\n",
        "    loss_list = np.array(loss_list)\n",
        "    acc_list = np.array(acc_list)\n",
        "\n",
        "    best_comb = np.argmax(acc_list)\n",
        "  \n",
        "  else:  \n",
        "    grid = ParamDomain(rand_params)\n",
        "    hyperpara_perm = list(itertools.product(*grid))\n",
        "    combinations = len(hyperpara_perm)\n",
        "    print(\"Total Number of Parameter Combinations that will be carried out: \", combinations)\n",
        "\n",
        "    for comb in range(combinations):\n",
        "      # CHANGE MODELS HERE!\n",
        "      model = LeNet5()\n",
        "      ll, l, a = test_hyperpara(hyperpara_perm[i++], model, train_loader, validate_loader)\n",
        "      lloss_list.append(ll)\n",
        "      loss_list.append(l)\n",
        "      acc_list.append(a)\n",
        "\n",
        "    lloss_list = np.array(lloss_list)\n",
        "    loss_list = np.array(loss_list)\n",
        "    acc_list = np.array(acc_list)\n",
        "\n",
        "    best_comb = np.argmax(acc_list)\n",
        "\n",
        "  if pseudo: print(\" - Pseudo Grid Search - \")\n",
        "  print(\"Best Accuracy Achieved: \", np.amax(acc_list))\n",
        "  print(\"The combination for the best params: \", best_comb)\n",
        "  \n",
        "  return best_comb, lloss_list, loss_list, acc_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLqQbdZDp0tF",
        "colab_type": "text"
      },
      "source": [
        "### Run Random-Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsTQxpjjSGuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting Up Datasets:\n",
        "X_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-imgs.npy\") /255\n",
        "y_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-labels.npy\")\n",
        "X_test_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-test-imgs.npy\") /255\n",
        "\n",
        "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(X_train_orig, y_train_orig)\n",
        "indices = [(t, v) for t, v in shuffler][0]\n",
        "\n",
        "X_train, y_train = X_train_orig[indices[0]].astype(float), y_train_orig[indices[0]]\n",
        "X_val, y_val = X_train_orig[indices[1]].astype(float), y_train_orig[indices[1]]\n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_val, y_val =  torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "\n",
        "mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "# Assemble tensor datasets\n",
        "train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=True, mean=mean, std=std)\n",
        "val_ds = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "# Assemble dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "# Run Search:\n",
        "# Random Search\n",
        "iterations = 15\n",
        "#max_acc, rand_params = RandomSearch(iterations, train_loader, val_loader)\n",
        "# Grid Search\n",
        "#best_comb, llosss, losss, accs = GridSearch(rand_params, train_loader, validate_loader, pseudo=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCvH4HlUe6hm",
        "colab_type": "text"
      },
      "source": [
        "## 4. Final Full Training\n",
        "\n",
        "Here we train the model onto the full training set and use the given test dataset for the Kaggle competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcGh6JpptkPt",
        "colab_type": "text"
      },
      "source": [
        "### Full Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUf9wyjQdR-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Full Datasets\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "X_test = X_test_orig.astype(float)\n",
        "\n",
        "# Dummy Test Labels\n",
        "y_test = torch.from_numpy(np.array(range(X_test.shape[0]))).float() \n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)\n",
        "\n",
        "mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=True, mean=mean, std=std)\n",
        "test_ds = CustomImageTensorDataset(X_test, y_test.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kDy5eRtoOM",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmAh5HeXteoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change model here:\n",
        "model = AlexNet_Exp24().to(device)\n",
        "\n",
        "# Train Model:\n",
        "set_seed(seed)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0, amsgrad=False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(n_epochs):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "    logs['val_' + 'log loss'] = 0.\n",
        "    logs['val_' + 'accuracy'] = 0.\n",
        "    \n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKWQs_-5tqhd",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90LE_S1TsJ-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model\n",
        "y_predictions, _ = evaluate(model, test_loader_full)\n",
        "\n",
        "idx = np.array(_)\n",
        "pred = np.array(y_predictions)\n",
        "\n",
        "submit = np.vstack((idx, pred))\n",
        "submit = submit.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VvUj4Z3tsr_",
        "colab_type": "text"
      },
      "source": [
        "### Save Submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_HFz2lv3vZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "model_save_name = \".pt\"\n",
        "path = F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/Model/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "# Save the submission\n",
        "output_save_name = \".txt\"\n",
        "path_out = F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/{output_save_name}\"\n",
        "np.savetxt(path_out, submit, delimiter=\",\", fmt='%d', header=\"Id,Category\", comments='')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}