{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_BackProp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0BUjqiFCAoAb",
        "AeK_f_DuyoeN",
        "XMp-qxiyAwLO",
        "NexrLXziyuBn",
        "bMSyyXEsA1OF",
        "kmYrWGVzMlf4",
        "Ud477csup2v7",
        "iNb6SrStmUjk",
        "dSYbi6kRmrLM",
        "eb9gWIPnnlCW",
        "47T54GxYn5La",
        "RcYYOISPTdsM",
        "fg-oQq6v7rEk",
        "d2bWXzcG7o8k",
        "MLqQbdZDp0tF",
        "LcGh6JpptkPt",
        "T0kDy5eRtoOM",
        "GKWQs_-5tqhd",
        "x9TJkY0pOnUC",
        "7VvUj4Z3tsr_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyKbeDHPxXYh",
        "colab_type": "text"
      },
      "source": [
        "# Team BackProp - Data Science Notebook\n",
        "\n",
        "During exploration of the neural architecture, we used copies of this notebook to be able to easily process data whilst keeping our models intact. \n",
        "\n",
        "The general overview of the data modelling pipeline is as follows:\n",
        "\n",
        "1. Import KMNIST Data\n",
        "2. Data preprocess and augmentate\n",
        "3. Develop neural network model\n",
        "4. Cross validate model\n",
        "    - At this stage we decide whether to keep the model for full training or remodify the network again to improve it.\n",
        "5. Hyperparameter Tuning\n",
        "6. Train on the full dataset\n",
        "7. Save model and Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPZJdQrwmPYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUjqiFCAoAb",
        "colab_type": "text"
      },
      "source": [
        "## Pipeline Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeK_f_DuyoeN",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRx8ivmoKxj",
        "colab_type": "code",
        "outputId": "e063f8b1-20d3-4848-a805-4ca7d6fb4b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Dataset \n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage, RandomResizedCrop, RandomAffine\n",
        "import random\n",
        "import itertools\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pickle\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwfMUJGoM8C",
        "colab_type": "code",
        "outputId": "deb1524d-4f99-4aee-fc2b-0eb111f37e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMp-qxiyAwLO",
        "colab_type": "text"
      },
      "source": [
        "### Import KMNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUPcM99Nmk_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the datasets\n",
        "X_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-imgs.npy\") /255\n",
        "y_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-labels.npy\")\n",
        "X_test_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-test-imgs.npy\") /255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3r09aK-nZUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the classmap as a dictionary\n",
        "classmap = {}\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist_classmap.csv', 'r') as csvfile:\n",
        "   spamreader = csv.reader(csvfile, delimiter=',')\n",
        "   next(spamreader)\n",
        "   for row in spamreader:\n",
        "       classmap[row[0]] = row[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ_PzPsjp5wN",
        "colab_type": "code",
        "outputId": "42fe1abe-07bd-4a36-c305-745a2b433e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# Check if we imported correctly\n",
        "plt.imshow(X_train_orig[104])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f390599b320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWH4ip1h+IqdYfiKn/g8sgxvrYTasrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NexrLXziyuBn",
        "colab_type": "text"
      },
      "source": [
        "## Processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2_MQndzlnz",
        "colab_type": "text"
      },
      "source": [
        "### Train, Validate and Evaluate Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqSyDu7jy0l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # the dimension here was changed to match our KMNIST's dimension\n",
        "        a2 = model(X.view(-1, 1, 28, 28).float()) \n",
        "        \n",
        "        loss = criterion(a2, y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            # the dimension here was changed to match our KMNIST's dimension\n",
        "            a2 = model(X.view(-1, 1, 28, 28).float())\n",
        "            \n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            # the dimension here was changed to match our KMNIST's dimension\n",
        "            a2 = model(X.view(-1, 1, 28, 28).float())\n",
        "            \n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9lUo_taNmHQ",
        "colab_type": "text"
      },
      "source": [
        "### Model Ensembling (functions to be used post trained models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZbhOq3sNrZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble_validate(model_list, criterion, data_loader):\n",
        "  \"\"\"To be passed a list of pre-trained models sent to GPU\n",
        "  RETURNS: validation accuracy of the ensembled model predictons\"\"\"\n",
        "    \n",
        "  for i in model_list:\n",
        "      i.eval()\n",
        "\n",
        "  validation_loss, validation_accuracy = 0., 0.\n",
        "  \n",
        "  a2 = 0\n",
        "\n",
        "  for X, y in data_loader:\n",
        "      with torch.no_grad():\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          for model in model_list:\n",
        "            # add the pre softmax values of all models\n",
        "            a2 += model(X.view(-1, 1, 28, 28).float())\n",
        "\n",
        "          a2 /= len(model_list)\n",
        "\n",
        "          # predictions based on multiple model averages\n",
        "          y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "\n",
        "          validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "\n",
        "  return validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "  \n",
        "def ensemble_evaluate(model_list, data_loader):\n",
        "  \"\"\"To be passed a list of pre-trained models sent to GPU\n",
        "  RETURNS: list of predicted ys based on ensembled models\"\"\"\n",
        "  for i in model_list:\n",
        "    i.eval()\n",
        "\n",
        "  a2 = 0\n",
        "  ys, y_preds = [], []\n",
        "\n",
        "  for X, y in data_loader:\n",
        "      with torch.no_grad():\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          for model in model_list:\n",
        "            # add the pre softmax values of all models\n",
        "            a2 += model(X.view(-1, 1, 28, 28).float())\n",
        "\n",
        "          a2 /= len(model_list)\n",
        "\n",
        "          y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "          ys.append(y.cpu().numpy())\n",
        "          y_preds.append(y_pred.cpu().numpy())\n",
        "\n",
        "  return np.concatenate(y_preds, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pxzJtTE1BF0",
        "colab_type": "text"
      },
      "source": [
        "### Training Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfDvaqlj1Ec7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(wd, lrt, model, train_loader, validate_loader):\n",
        "  set_seed(seed)\n",
        "  model = model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lrt, betas=(0.9, 0.999), eps=1e-08, weight_decay=wd, amsgrad=False)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(n_epochs):\n",
        "      logs = {}\n",
        "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "      logs['' + 'log loss'] = train_loss.item()\n",
        "      logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "      validation_loss, validation_accuracy = validate(model, criterion, validate_loader)\n",
        "      logs['val_' + 'log loss'] = validation_loss.item()\n",
        "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "      liveloss.update(logs)\n",
        "      liveloss.draw()\n",
        "\n",
        "  return liveloss, validation_loss, validation_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rexhWjRYy71X",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6FQzIZ_zDKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold_datasets(n_splits, X_train_orig, y_train_orig, trans=True, verbatim=False):\n",
        "  '''Wrapper function that returns a list of train/val datasets which have been \n",
        "     subjected to the KFold method. \n",
        "  '''\n",
        "  \n",
        "  kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  fold_train_loader = [] # list of shuffled training dataloaders\n",
        "  fold_validation_loader = [] # list of shuffled validation dataloaders\n",
        "\n",
        "  for train_index, test_index in kf.split(X_train_orig, y_train_orig):\n",
        "    if verbatim: print(\"TRAIN:\", train_index, \"Validation:\", test_index)\n",
        "    X_train, X_val = X_train_orig[train_index], X_train_orig[test_index]\n",
        "    y_train, y_val = y_train_orig[train_index], y_train_orig[test_index]\n",
        "\n",
        "    if verbatim: print(\"train size:\", X_train.shape, \"test size:\", X_val.shape)\n",
        "\n",
        "    # Convert to tensor\n",
        "    X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "    X_val, y_val = torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "    \n",
        "    # Find mean std\n",
        "    mean1, std1 = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "    # make Custom set\n",
        "    train_dataset = CustomImageTensorDataset(X_train, y_train.long(), transform=trans, mean=mean1, std=std1)\n",
        "    validation_dataset = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean1, std=std1)\n",
        "\n",
        "    # initialize the data-loaders\n",
        "    fold_train_loader.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4))\n",
        "    fold_validation_loader.append(DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NN7nOVyzxdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_kfold(wd, lrt, fold_train_loader, fold_validation_loader):\n",
        "  \"\"\" function to easily train the model with weight_decay as input parameter.\n",
        "  \n",
        "      HOW TO RUN THE FUNCTION:\n",
        "      fold_train_loader, fold_validation_loader = kfold_datasets(5, X_train_orig, y_train_orig, False)\n",
        "      lloss, loss, acc = train_model_kfold(weight_decay[3], fold_train_loader, fold_validation_loader)\n",
        "  \"\"\"\n",
        "  \n",
        "  fold_liveloss = []\n",
        "  fold_loss = 0.\n",
        "  fold_acc = 0.\n",
        "  for fold in range(len(fold_train_loader)):\n",
        "    # CHANGE THE MODEL HERE:\n",
        "    model = LeNet5()\n",
        "\n",
        "    liveloss, val_loss, val_acc = train_model(wd, lrt, model, fold_train_loader[fold], fold_validation_loader[fold])\n",
        "    fold_liveloss.append(liveloss)\n",
        "    fold_loss += val_loss\n",
        "    fold_acc += val_acc\n",
        "    print(\"fold:\", fold)\n",
        "    \n",
        "  print(\"Averaged Accuracy: \", (fold_acc/len(fold_train_loader))*100)\n",
        "  return fold_liveloss, fold_loss, fold_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMSyyXEsA1OF",
        "colab_type": "text"
      },
      "source": [
        "## Image Preprocessing and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8JjQRgsWMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomImageTensorDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None, mean=False, std=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data.reshape(-1,1,28,28)\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "        # Find mean and standard dev\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "        \n",
        "        self.Rotation = Compose([\n",
        "                                  ToPILImage(),\n",
        "                                   RandomRotation(10),\n",
        "                                   ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                ])\n",
        "\n",
        "        self.RotandCrop = Compose([\n",
        "                                  ToPILImage(),\n",
        "                                   RandomResizedCrop(size=(28,28), scale=(0.8,1)),\n",
        "                                  ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                 ])\n",
        "        \n",
        "        self.Affine = Compose([ToPILImage(),\n",
        "                                   RandomAffine(10, shear=10),\n",
        "                                   ToTensor(), Normalize(mean=[self.mean], std=[self.std])\n",
        "                                ])\n",
        " \n",
        "        \n",
        "        self.Norm = Compose([Normalize(mean=[self.mean], std=[self.std])\n",
        "                                 ])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        assert (self.mean != False), \"Asign a mean\"\n",
        "        assert (self.mean != False), \"Asign a std\"\n",
        "        \n",
        "        if self.transform:\n",
        "            x = random.random()\n",
        "            if 0<= x<0.2: # rotate\n",
        "              sample = self.Rotation(sample)\n",
        "            if 0.2<= x<0.4: # resize crop\n",
        "              sample = self.RotandCrop(sample)\n",
        "            if 0.4<= x<0.7: # shear crop\n",
        "              sample= self.Affine(sample)\n",
        "              \n",
        "            else: # none\n",
        "              sample = self.Norm(sample)\n",
        "        else:\n",
        "           sample = self.Norm(sample)\n",
        "            \n",
        "        return sample, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBQNzrYJ7PEM",
        "colab_type": "code",
        "outputId": "58ed39a3-09a0-4afc-ea42-f8c86e5d4d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "# Check if our data augmentation/preprocessing works\n",
        "\n",
        "# Create a new custom image dataset:\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "mean1, std1 = torch.mean(X_train), torch.std(X_train)\n",
        "dset = CustomImageTensorDataset(X_train, y_train, transform=True, mean=mean1, std=std1 )\n",
        "\n",
        "# Make a dataloader to access the PIL images of a batch size of 25\n",
        "loader = DataLoader(dset, batch_size=25, shuffle=True)\n",
        "\n",
        "# Create an iter object to cycle through dataloader\n",
        "train_iter = iter(loader)\n",
        "imgs, labels = train_iter.next()\n",
        "\n",
        "print(imgs.shape)\n",
        "print('max:',imgs.max())\n",
        "\n",
        "# plot our batch of images with label names\n",
        "fig, axarr = plt.subplots(5,5,figsize=(8,8))\n",
        "fig.tight_layout()\n",
        "for img, label, axs in zip(imgs, labels, axarr.flatten()):\n",
        "    axs.set_title(classmap[str(label.numpy())] + \"   \" + str(label.numpy()))\n",
        "    axs.imshow(img.numpy()[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25, 1, 28, 28])\n",
            "max: tensor(6.1103)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAI6CAYAAADWqBk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmYrWGVzMlf4",
        "colab_type": "text"
      },
      "source": [
        "## Redistribution of classes in training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UziHwj3sMrWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_data(X_train=X_train, y_train=y_train, four=2, two=1):\n",
        "  \"\"\"param four and two stand for the number times to add the respective classes\n",
        "  back into the dataset\"\"\"\n",
        "  # find index of classes\n",
        "  index_4 = np.where(y_train == 4)\n",
        "  index_2 = np.where(y_train == 2)\n",
        "\n",
        "  # find the images from 4 and 2\n",
        "  images_4 = X_train[index_4]\n",
        "  images_2 = X_train[index_2]\n",
        "\n",
        "  # find labels\n",
        "  labels_4 = y_train[index_4]\n",
        "  labels_2 = y_train[index_2]\n",
        "\n",
        "\n",
        "  for i in range(four): # how many times the set of 4\n",
        "    X_train = np.concatenate((X_train, images_4))\n",
        "    y_train = np.concatenate((y_train, labels_4))\n",
        "\n",
        "\n",
        "  for i in range(two): # how many times the set of 2\n",
        "    y_train = np.concatenate((y_train, labels_2))\n",
        "    X_train = np.concatenate((X_train, images_2))\n",
        "  \n",
        "  return X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VMPIn0zMslq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dist(y_train):\n",
        "  \"\"\"Plot the distribution of the training data\"\"\"\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.hist(y_train, bins='auto')\n",
        "  plt.title(\"Distribution of classes in the training set\", fontsize=20)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Z6KgcmM6pJ",
        "colab_type": "code",
        "outputId": "5dd1e654-3ae7-4b42-dc17-46680211203b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# Create Full Datasets\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "\n",
        "# add 2*four and 1*two into the data\n",
        "X_train, y_train = add_data(four=1, two=0)\n",
        "\n",
        "plot_dist(y_train)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAFECAYAAACNoPIqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB41PZXXf+EEkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrW2caLupYqs",
        "colab_type": "text"
      },
      "source": [
        "## 1. Model Development\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud477csup2v7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Architecture Analysis Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7Xk3rwp11R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp1(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp1, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(400, 256, bias=True)\n",
        "    self.output = nn.Linear(256, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zToYy7v-sgrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp3(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 4x to better fit to the labels compared to 8x scaling\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp3, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=2, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(800, 512, bias=True)\n",
        "    self.output = nn.Linear(512, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG80gvW7U9sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp4(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      We have now provided a \"reasonable\" guess of the filters and paddings \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp4, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(144, 128, bias=True)\n",
        "    self.output = nn.Linear(128, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9B3jjq2scot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp5(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of layers and parameters \n",
        "      are rescaled down by 8x but with an addional convolutional layer \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp5, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    \n",
        "    # additional layer\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    \n",
        "    self.conv_7 = nn.Conv2d(24, 24, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_10 = nn.Linear(144, 100, bias=True)\n",
        "    self.output = nn.Linear(100, 10, bias=True)\n",
        "    \n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    \n",
        "    x = self.act(self.conv_6(x))\n",
        "    \n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.act(self.conv_8(x))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ_3_vYFFgM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp6(nn.Module):\n",
        "  \"\"\" Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 4x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      We have now provided a \"reasonable\" guess of the filters and paddings \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp6, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(288, 200, bias=True)\n",
        "    self.output = nn.Linear(200, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD0WhU72wmri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp7(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper with the same number of channels and layers \n",
        "      are rescaled down by 8x to fit with the original alexnet image size to \n",
        "      our kmnist size ratio (227:28)\n",
        "      \n",
        "      +1 classification layer\n",
        "      \n",
        "      We provided a \"reasonable\" guess of the filters\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp7, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=11, stride=1, padding=3, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(16, 24, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(24, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.conv_7 = nn.Conv2d(24, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.linear_9 = nn.Linear(144, 100, bias=True)\n",
        "    self.linear_10 = nn.Linear(100, 70, bias=True)\n",
        "    self.output = nn.Linear(70, 10, bias=True)\n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_9(x))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1NAO0w07E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp8(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +4 Classification layers\n",
        "      +x4 parameters\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp8, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 12, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(12, 32, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(48, 48, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(48, 48, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(48, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(288, 200, bias=True)\n",
        "    self.linear_11 = nn.Linear(200, 130, bias=True)\n",
        "    self.linear_12 = nn.Linear(130, 90, bias=True)\n",
        "    self.linear_13 = nn.Linear(90, 60, bias=True)\n",
        "    self.linear_14 = nn.Linear(60, 30, bias=True)\n",
        "    self.output = nn.Linear(30, 10, bias=True)\n",
        "    \n",
        "    #self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.conv_1(x))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.conv_3(x))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.conv_5(x))\n",
        "    x = self.act(self.conv_6(x))\n",
        "    x = self.act(self.conv_7(x))\n",
        "    x = self.act(self.conv_8(x))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.linear_10(x))\n",
        "    x = self.act(self.linear_11(x))\n",
        "    x = self.act(self.linear_12(x))\n",
        "    x = self.act(self.linear_13(x))\n",
        "    x = self.act(self.linear_14(x))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTkKwEBHA3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp12(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +5 Classification layers\n",
        "      +x2 parameters - only halved the original params!\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      Added batch norm\n",
        "      Added drop out\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp12, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 24, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(24, 64, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(64, 96, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(96, 96, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(96, 96, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(96, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(576, 384, bias=True)\n",
        "    self.linear_11 = nn.Linear(384, 192, bias=True)\n",
        "    self.linear_12 = nn.Linear(192, 128, bias=True)\n",
        "    self.linear_13 = nn.Linear(128, 85, bias=True)\n",
        "    self.linear_14 = nn.Linear(85, 42, bias=True)\n",
        "    self.linear_15 = nn.Linear(42, 21, bias=True)\n",
        "    self.output = nn.Linear(21, 10, bias=True)\n",
        "    \n",
        "    # Batch Normalization\n",
        "    self.b1 = nn.BatchNorm2d(24)\n",
        "    self.b3 = nn.BatchNorm2d(64)\n",
        "    self.b5 = nn.BatchNorm2d(96)\n",
        "    self.b6 = nn.BatchNorm2d(96)\n",
        "    self.b7 = nn.BatchNorm2d(96)\n",
        "    self.b8 = nn.BatchNorm2d(64)\n",
        "    \n",
        "    self.dout = nn.Dropout(p=0.25) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.b1(self.conv_1(x)))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.b3(self.conv_3(x)))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.b5(self.conv_5(x)))\n",
        "    x = self.act(self.b6(self.conv_6(x)))\n",
        "    x = self.act(self.b7(self.conv_7(x)))\n",
        "    x = self.act(self.b8(self.conv_8(x)))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.dout(self.linear_10(x)))\n",
        "    x = self.act(self.dout(self.linear_11(x)))\n",
        "    x = self.act(self.dout(self.linear_12(x)))\n",
        "    x = self.act(self.dout(self.linear_13(x)))\n",
        "    x = self.act(self.dout(self.linear_14(x)))\n",
        "    x = self.act(self.dout(self.linear_15(x)))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWwKvQJlGBgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet_Exp24(nn.Module):\n",
        "  \"\"\"Based on the AlexNet paper: Modified the each part of the network\n",
        "      +1 Conv layer\n",
        "      +5 Classification layers\n",
        "      +x2 parameters - only halved the original params!\n",
        "      We have used a \"reasonable\" guess of the filters \n",
        "      Added batch norm\n",
        "      Added drop out\n",
        "      \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(AlexNet_Exp24, self).__init__()\n",
        "    # Convolutional Layers\n",
        "    self.conv_1 = nn.Conv2d(1, 16, kernel_size=13, stride=1, padding=6, bias=True)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_3 = nn.Conv2d(16, 42, kernel_size=7, stride=1, padding=3, bias=True)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv_5 = nn.Conv2d(42, 64, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "    self.conv_6 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2, bias=True)    \n",
        "    self.conv_7 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=1, bias=True)\n",
        "    self.conv_8 = nn.Conv2d(64, 42, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "    self.pool_9 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # Classification Layers\n",
        "    self.linear_10 = nn.Linear(378, 252, bias=True)\n",
        "    self.linear_11 = nn.Linear(252, 126, bias=True)\n",
        "    self.linear_12 = nn.Linear(126, 84, bias=True)\n",
        "    self.linear_13 = nn.Linear(84, 42, bias=True)\n",
        "    self.linear_14 = nn.Linear(42, 21, bias=True)\n",
        "    self.output = nn.Linear(21, 10, bias=True)\n",
        "    \n",
        "    # Batch Normalization\n",
        "    self.b1 = nn.BatchNorm2d(16)\n",
        "    self.b3 = nn.BatchNorm2d(42)\n",
        "    self.b5 = nn.BatchNorm2d(64)\n",
        "    self.b6 = nn.BatchNorm2d(64)\n",
        "    self.b7 = nn.BatchNorm2d(64)\n",
        "    self.b8 = nn.BatchNorm2d(42)\n",
        "    \n",
        "    self.dout = nn.Dropout(p=0.5) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.b1(self.conv_1(x)))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.b3(self.conv_3(x)))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.b5(self.conv_5(x)))\n",
        "    x = self.act(self.b6(self.conv_6(x)))\n",
        "    x = self.act(self.b7(self.conv_7(x)))\n",
        "    x = self.act(self.b8(self.conv_8(x)))\n",
        "    x = self.pool_9(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.dout(self.linear_10(x)))\n",
        "    x = self.act(self.dout(self.linear_11(x)))\n",
        "    x = self.act(self.dout(self.linear_12(x)))\n",
        "    x = self.act(self.dout(self.linear_13(x)))\n",
        "    x = self.act(self.dout(self.linear_14(x)))\n",
        "    x = self.output(x) # Don't activate this output layer, we apply a softmax transformation in our training functions!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNb6SrStmUjk",
        "colab_type": "text"
      },
      "source": [
        "### Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaqVRx4AmSLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleAlexNet_FINAL(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleAlexNet_FINAL, self).__init__()\n",
        "    self.conv_1 = nn.Conv2d(1, 36, kernel_size=3, padding=1)\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv_3 = nn.Conv2d(36, 72, kernel_size=3)\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv_5 = nn.Conv2d(72, 142, kernel_size=3, padding=1)\n",
        "    self.conv_6 = nn.Conv2d(142, 284, kernel_size=3, padding=1)\n",
        "    self.conv_7 = nn.Conv2d(284, 124, kernel_size=3, padding=1)\n",
        "    self.pool_8 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.linear_9 = nn.Linear(1116, 400)\n",
        "    self.linear_10 = nn.Linear(400, 400)\n",
        "    self.linear_11 = nn.Linear(400, 10)\n",
        "    self.dout = nn.Dropout(p=0.7) #dropout added to prevent overfitting :0\n",
        "    self.act = nn.ReLU()\n",
        "    self.b1 = nn.BatchNorm2d(36)\n",
        "    self.b2 = nn.BatchNorm2d(72)\n",
        "    self.b3 = nn.BatchNorm2d(142)\n",
        "    self.b4 = nn.BatchNorm2d(284)\n",
        "    self.b5 = nn.BatchNorm2d(124)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.b1(self.conv_1(x)))\n",
        "    x = self.pool_2(x)\n",
        "    x = self.act(self.b2(self.conv_3(x)))\n",
        "    x = self.pool_4(x)\n",
        "    x = self.act(self.b3(self.conv_5(x)))\n",
        "    x = self.act(self.b4(self.conv_6(x)))\n",
        "    x = self.act(self.b5(self.conv_7(x)))\n",
        "#     x = self.act(self.conv_7(x)) # Added new layer\n",
        "    x = self.pool_8(x)\n",
        "    x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "    x = self.act(self.dout(self.linear_9(x)))\n",
        "    x = self.act(self.dout(self.linear_10(x)))\n",
        "   # x = self.dout(x)\n",
        "    x = self.act(self.linear_11(x))\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSYbi6kRmrLM",
        "colab_type": "text"
      },
      "source": [
        "## 2. Cross Validation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTqJmL_YnFIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Cross_Validate(wd, lrt, transform=True, KFOLD=False, KFOLD_num=5):  \n",
        "  '''Wrapper function to choose to run either K-Fold Cross Validation or Single \n",
        "      Cross Validation.\n",
        "  '''\n",
        "  if KFOLD:\n",
        "    fold_train_loader, fold_validation_loader = kfold_datasets(KFOLD_num, X_train_orig, y_train_orig, False)\n",
        "    lloss, val_loss, val_acc = train_model_kfold(wd, lrt, fold_train_loader, fold_validation_loader)  \n",
        "  \n",
        "  else:\n",
        "    # Split into train and validation sets!\n",
        "    shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(X_train_orig, y_train_orig)\n",
        "    indices = [(t, v) for t, v in shuffler][0]\n",
        "    \n",
        "    X_train, y_train = X_train_orig[indices[0]].astype(float), y_train_orig[indices[0]]\n",
        "    X_val, y_val = X_train_orig[indices[1]].astype(float), y_train_orig[indices[1]]\n",
        "\n",
        "    X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "    X_val, y_val =  torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "\n",
        "    mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "    # Assemble tensor datasets\n",
        "    train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=transform, mean=mean, std=std)\n",
        "    val_ds = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "    # Assemble dataloaders\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "    \n",
        "    # CHANGE MODEL HERE:\n",
        "    model = SimpleAlexNet_FINAL().to(device)\n",
        "    lloss, val_loss, val_acc = train_model(wd, lrt, model, train_loader, val_loader)\n",
        "\n",
        "  return lloss, val_loss, val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9gWIPnnlCW",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnC8OBoanuvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialise training parameters:\n",
        "seed = 42\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmiv3rw6nryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run cross validation:\n",
        "lloss, val_loss, val_acc = Cross_Validate(0.0, 1e-4, transform=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47T54GxYn5La",
        "colab_type": "text"
      },
      "source": [
        "### Save Cross Validation Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtIg0iXCnzIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SimpleAlexNet_FINAL_logs = lloss.logs\n",
        "f = open(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/Model/SimpleAlexNet_FINAL_logs.pkl\",\"wb\")\n",
        "pickle.dump(SimpleAlexNet_FINAL_logs,f)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcYYOISPTdsM",
        "colab_type": "text"
      },
      "source": [
        "### Plot Misclassified Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtyxK6zTh9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_poorly_classified(y_actual, y_predictions):\n",
        "  \n",
        "  y_actual = np.array(y_actual)\n",
        "  y_predictions = np.array(y_predictions)\n",
        "  \n",
        "  a = np.where(y_actual != y_predictions)\n",
        "  wrong = y_actual[a]\n",
        "  \n",
        "  count, clss = np.histogram(wrong, bins=9)\n",
        "  \n",
        "  sorted(zip(count, clss), reverse=True)[:3]\n",
        "  \n",
        "  worst = sorted(zip(count, clss), reverse=True)[:3]\n",
        " \n",
        "  print(\"# Incorrect, Class ID:\", worst)\n",
        "  print('Worst 3 classified:', [ (classmap[str(int(i[1]))], i[1] ) for i in worst])\n",
        "  \n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.hist(wrong)\n",
        "  plt.title(\"Distribution of incorrect classifiactions\", fontsize=20)\n",
        "  plt.savefig(F\"/content/gdrive/My Drive/Colab Notebooks/after_peaks_on1,2,4,5.png\")\n",
        "  plt.show()\n",
        "  \n",
        "plot_poorly_classified(y_test, y_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGyT7utqloZq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Hyperparameter Tuning\n",
        "\n",
        "Hyper parameter searching has been turned off for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg-oQq6v7rEk",
        "colab_type": "text"
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbQCwZ7Q0t6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomSearch(iterations, train_loader, validate_loader):\n",
        "  max_acc = 0.0\n",
        "  opt_wd = 0.0\n",
        "  opt_lr = 0.0\n",
        "  \n",
        "  set_seed(seed)\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    # randomise our hyper parameters\n",
        "    weight_decay = 0.0\n",
        "    lr = 0.0 \n",
        "    \n",
        "    # Select from ranges of [1e-3 to 1e-7]\n",
        "    while np.isclose(weight_decay, 0.0):\n",
        "      power = int((random.random()*10)%6)+3\n",
        "      weight_decay = (5.*round(random.random()*10./5.) * (1./10.**power))\n",
        "\n",
        "    # Select from ranges of [1e-3 to 1e-6]\n",
        "    while np.isclose(lr, 0.0):\n",
        "      power = int((random.random()*10)%5)+3 \n",
        "      lr = 5.*round(random.random()*10./5.) * (1./10.**power)\n",
        "\n",
        "    print(\"Weight Decay: \", weight_decay)\n",
        "    print(\"Learn Rate: \", lr)\n",
        "    \n",
        "    # Change Model Here:\n",
        "    model = LeNet5()\n",
        "    lloss, val_loss, val_acc = train_model(weight_decay, lr, model, train_loader, validate_loader)\n",
        "\n",
        "    if val_acc > max_acc:\n",
        "      max_acc = val_acc\n",
        "      opt_wd = weight_decay\n",
        "      opt_lr = lr\n",
        "\n",
        "    return max_acc, [opt_wd, opt_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2bWXzcG7o8k",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZICLtlo587C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ParamDomain(params, range3=True):\n",
        "  grid_search = []\n",
        "  \n",
        "  for param in params:\n",
        "    count = 0\n",
        "    number = 1/param\n",
        "    s = set(str(param))\n",
        "    isFive = s.issuperset(\"5\")\n",
        "\n",
        "    while (number > 0):\n",
        "      number = number//10\n",
        "      count = count + 1\n",
        "    if not isFive:\n",
        "      count = count - 1\n",
        "    num = (1.0/10.0**count)\n",
        "    \n",
        "    if range3:\n",
        "      param_domain = []\n",
        "      param_domain.append(param - num*1)\n",
        "      param_domain.append(param)\n",
        "      param_domain.append(param + num*1)\n",
        "    else:\n",
        "      param_domain = []\n",
        "      param_domain.append(param - num*2)\n",
        "      param_domain.append(param - num*1)\n",
        "      param_domain.append(param)\n",
        "      param_domain.append(param + num*1)\n",
        "      param_domain.append(param + num*2)\n",
        "    \n",
        "    grid_search.append(param_domain)\n",
        "    \n",
        "  return grid_search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFzQVrhBcUPz",
        "colab_type": "code",
        "outputId": "8267bad9-bbc7-4306-c430-260acafedd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "def test_hyperpara(one_hyperpara, model, train_loader, validate_loader):\n",
        "  wd, lrt = one_hyperpara\n",
        "  lloss, loss, acc = train_model(wd, lrt, model, train_loader, validate_loader)\n",
        "  return lloss, loss, acc\n",
        "  \n",
        "def GridSearch(rand_params, train_loader, validate_loader, pseudo=True):\n",
        "  i = 0\n",
        "  lloss_list, loss_list, acc_list = [], [], []\n",
        "\n",
        "  if pseudo: # In grid search we may want to only find only the combinations that vary contiguously\n",
        "    grid = ParamDomain(params, False)\n",
        "    grid = np.array(grid)\n",
        "    grid = grid.transpose()\n",
        "    print(\"Total number of side by side searches: \", grid.shape[0])\n",
        "\n",
        "    for comb in grid:\n",
        "      # CHANGE MODELS HERE!\n",
        "      model = LeNet5()\n",
        "      wd = comb[0]\n",
        "      lrt = comb[1]\n",
        "      #mtm = comb[2]\n",
        "      \n",
        "      ll, l, a = train_model(wd, lrt, model, train_loader, validate_loader)\n",
        "      lloss_list.append(ll)\n",
        "      loss_list.append(l)\n",
        "      acc_list.append(a)\n",
        "      \n",
        "    lloss_list = np.array(lloss_list)\n",
        "    loss_list = np.array(loss_list)\n",
        "    acc_list = np.array(acc_list)\n",
        "\n",
        "    best_comb = np.argmax(acc_list)\n",
        "  \n",
        "  else:  \n",
        "    grid = ParamDomain(rand_params)\n",
        "    hyperpara_perm = list(itertools.product(*grid))\n",
        "    combinations = len(hyperpara_perm)\n",
        "    print(\"Total Number of Parameter Combinations that will be carried out: \", combinations)\n",
        "\n",
        "    for comb in range(combinations):\n",
        "      # CHANGE MODELS HERE!\n",
        "      model = LeNet5()\n",
        "      ll, l, a = test_hyperpara(hyperpara_perm[i++], model, train_loader, validate_loader)\n",
        "      lloss_list.append(ll)\n",
        "      loss_list.append(l)\n",
        "      acc_list.append(a)\n",
        "\n",
        "    lloss_list = np.array(lloss_list)\n",
        "    loss_list = np.array(loss_list)\n",
        "    acc_list = np.array(acc_list)\n",
        "\n",
        "    best_comb = np.argmax(acc_list)\n",
        "\n",
        "  if pseudo: print(\" - Pseudo Grid Search - \")\n",
        "  print(\"Best Accuracy Achieved: \", np.amax(acc_list))\n",
        "  print(\"The combination for the best params: \", best_comb)\n",
        "  \n",
        "  return best_comb, lloss_list, loss_list, acc_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-ca8df4724689>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    ll, l, a = test_hyperpara(hyperpara_perm[i++], model, train_loader, validate_loader)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLqQbdZDp0tF",
        "colab_type": "text"
      },
      "source": [
        "### Run Random-Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsTQxpjjSGuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting Up Datasets:\n",
        "X_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-imgs.npy\") /255\n",
        "y_train_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-train-labels.npy\")\n",
        "X_test_orig = np.load(F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/acse-module-8-19/kmnist-test-imgs.npy\") /255\n",
        "\n",
        "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(X_train_orig, y_train_orig)\n",
        "indices = [(t, v) for t, v in shuffler][0]\n",
        "\n",
        "X_train, y_train = X_train_orig[indices[0]].astype(float), y_train_orig[indices[0]]\n",
        "X_val, y_val = X_train_orig[indices[1]].astype(float), y_train_orig[indices[1]]\n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_val, y_val =  torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n",
        "\n",
        "mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "# Assemble tensor datasets\n",
        "train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=True, mean=mean, std=std)\n",
        "val_ds = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "# Assemble dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "n_epochs=30\n",
        "\n",
        "# Run Search:\n",
        "# Random Search\n",
        "iterations = 15\n",
        "#max_acc, rand_params = RandomSearch(iterations, train_loader, val_loader)\n",
        "\n",
        "# Grid Search\n",
        "#best_comb, llosss, losss, accs = GridSearch(rand_params, train_loader, validate_loader, pseudo=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCvH4HlUe6hm",
        "colab_type": "text"
      },
      "source": [
        "## 4. Final Full Training\n",
        "\n",
        "Here we train the model onto the full training set and use the given test dataset for the Kaggle competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcGh6JpptkPt",
        "colab_type": "text"
      },
      "source": [
        "### Full Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUf9wyjQdR-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Full Datasets\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "X_test = X_test_orig.astype(float)\n",
        "\n",
        "# Dummy Test Labels for y_test\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(np.array(range(X_test.shape[0]))).float() \n",
        "\n",
        "mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=True, mean=mean, std=std)\n",
        "test_ds = CustomImageTensorDataset(X_test, y_test.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kDy5eRtoOM",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmAh5HeXteoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change model here:\n",
        "model = SimpleAlexNet_FINAL().to(device)\n",
        "\n",
        "# Train Model:\n",
        "set_seed(seed)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0, amsgrad=False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(n_epochs):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "    logs['val_' + 'log loss'] = 0.\n",
        "    logs['val_' + 'accuracy'] = 0.\n",
        "    \n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKWQs_-5tqhd",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90LE_S1TsJ-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model\n",
        "y_predictions, _ = evaluate(model, test_loader_full)\n",
        "\n",
        "idx = np.array(_)\n",
        "pred = np.array(y_predictions)\n",
        "\n",
        "submit = np.vstack((idx, pred))\n",
        "submit = submit.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9TJkY0pOnUC",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik27VgbvOqNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list = [] # to be filled with pre-trained models on the cpu\n",
        "\n",
        "train_loader_full = DataLoader(train_ds, batch_size=1000, shuffle=False, num_workers=0)\n",
        "test_loader_full = DataLoader(test_ds, batch_size=1000, shuffle=False, num_workers=0)\n",
        "\n",
        "ensemble_score = ensemble_validate(model_list, criterion=nn.CrossEntropyLoss(), data_loader=test_loader_full)\n",
        "    \n",
        "print('Score for the predictions of the ensembled models:', ensemble_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VvUj4Z3tsr_",
        "colab_type": "text"
      },
      "source": [
        "### Save Submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_HFz2lv3vZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "model_save_name = \".pt\"\n",
        "path = F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/Model/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "# Save the submission\n",
        "output_save_name = \".txt\"\n",
        "path_out = F\"/content/gdrive/My Drive/Colab Notebooks/Mini-Project/{output_save_name}\"\n",
        "np.savetxt(path_out, submit, delimiter=\",\", fmt='%d', header=\"Id,Category\", comments='')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}